{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework 3 - Data Analytics with Spark.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Instalasi OpenJDK karena Spark ditulis dalam bahasa Scala dan berjalan di atas Java Virtual Machine (JVM)."
      ],
      "metadata": {
        "id": "gWFrIzBoARSz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bysajzv_vage"
      },
      "outputs": [],
      "source": [
        "# OpenJDK\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Spark with Hadoop dan extract."
      ],
      "metadata": {
        "id": "KDYsw0dCAU1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Spark\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "Wv05NqSyvkFS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set environment PATH"
      ],
      "metadata": {
        "id": "FTGtouzmAYEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop2.7/bin\""
      ],
      "metadata": {
        "id": "OS5pvRu5vmMU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install library **Findspark** yang akan mencari spark dalam sistem dan akan menginstallnya sebagai regular library."
      ],
      "metadata": {
        "id": "RenxAIGFAat8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark\n",
        "import findspark\n",
        "findspark.init(\"/content/spark-3.2.1-bin-hadoop2.7/\", edit_rc=True)"
      ],
      "metadata": {
        "id": "QbmB8Sqpvoq1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import **SparkSession** dari pyspark.sql and membuat SparkSession"
      ],
      "metadata": {
        "id": "yFbL55MTAbk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()"
      ],
      "metadata": {
        "id": "hU2ZAxUdvqk0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jalankan `spark` untuk melihat info dari Spark"
      ],
      "metadata": {
        "id": "RNnlAtOHAgD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "6LS3O27Tvruq",
        "outputId": "6cf5266c-5d9e-4ce8-e924-1cf668225df3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://74ccf7f25126:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Colab</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f8d9ce320d0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuat data `emp` dan `dept` beserta schema-nya"
      ],
      "metadata": {
        "id": "AvTOVX-zAg8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emp = [\n",
        "       (1, \"Smith\", -1, \"2018\", \"10\", \"M\", 3000), \\\n",
        "       (2, \"Rose\", 1, \"2010\", \"20\", \"M\", 4000), \\\n",
        "       (3, \"Williams\", 1, \"2010\", \"10\", \"M\", 1000), \\\n",
        "       (4, \"Jones\", 2, \"2005\", \"10\", \"F\", 2000), \\\n",
        "       (5, \"Brown\", 2, \"2010\", \"40\", \"\", -1), \\\n",
        "       (6, \"Brown\", 2, \"2010\", \"50\", \"\", -1) \\\n",
        "      ]\n",
        "\n",
        "empColumns = [\"emp_id\", \"name\", \"superior_emp_id\", \"year_joined\", \\\n",
        "              \"emp_dept_id\", \"gender\", \"salary\"]\n",
        "\n",
        "dept = [(\"Finance\", 10), \\\n",
        "        (\"Marketing\", 20), \\\n",
        "        (\"Sales\", 30), \\\n",
        "        (\"IT\", 40) \\\n",
        "      ]\n",
        "\n",
        "deptColumns = [\"dept name\", \"dept id\"]"
      ],
      "metadata": {
        "id": "O9j12BdrvsOm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Memasukkan data dan juga schema ke dalam spark dataframe"
      ],
      "metadata": {
        "id": "dqtqyxSzAsRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emp_df = spark.createDataFrame(data=emp, schema=empColumns)\n",
        "dept_df = spark.createDataFrame(data=dept, schema=deptColumns)"
      ],
      "metadata": {
        "id": "uD5cDGicwXWN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan data `emp`"
      ],
      "metadata": {
        "id": "dn2VbS3IAwpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emp_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJhGkcifyBLP",
        "outputId": "6cc9843b-529e-4f20-8857-4768e814a77d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+---------------+-----------+-----------+------+------+\n",
            "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
            "+------+--------+---------------+-----------+-----------+------+------+\n",
            "|     1|   Smith|             -1|       2018|         10|     M|  3000|\n",
            "|     2|    Rose|              1|       2010|         20|     M|  4000|\n",
            "|     3|Williams|              1|       2010|         10|     M|  1000|\n",
            "|     4|   Jones|              2|       2005|         10|     F|  2000|\n",
            "|     5|   Brown|              2|       2010|         40|      |    -1|\n",
            "|     6|   Brown|              2|       2010|         50|      |    -1|\n",
            "+------+--------+---------------+-----------+-----------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan data `dept`"
      ],
      "metadata": {
        "id": "kdcSpudiA0Bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dept_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJ-U-XURyCRM",
        "outputId": "760ad9b2-bb40-462c-e084-1d084ebe981a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+\n",
            "|dept name|dept id|\n",
            "+---------+-------+\n",
            "|  Finance|     10|\n",
            "|Marketing|     20|\n",
            "|    Sales|     30|\n",
            "|       IT|     40|\n",
            "+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada tabel `emp`, terdapat kolom `emp_dept_id` yang merujuk pada tabel `dept`. Hanya saja, nama kolom pada tabel `dept` perlu diubah agar dapat dilakukan join."
      ],
      "metadata": {
        "id": "8Lo1KIg0A358"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ubah nama kolom\n",
        "new_dept_df = dept_df.withColumnRenamed('dept name', 'dept_name').withColumnRenamed('dept id', 'dept_id')\n",
        "new_dept_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa_7Tk6LzTWK",
        "outputId": "5c68f579-77c9-449e-dd7e-7c50b2492657"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- dept_name: string (nullable = true)\n",
            " |-- dept_id: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Join kedua tabel dimana `new_dept_df.dept_id` sama dengan `emp_df.emp_dept_id`."
      ],
      "metadata": {
        "id": "xuKcwdTNBM35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inner Join \n",
        "joined_df = emp_df.join(new_dept_df,emp_df.emp_dept_id ==  new_dept_df.dept_id,\"inner\")\n",
        "joined_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qc_YgbAlyFzy",
        "outputId": "27d71160-807f-4da0-b2e3-1dd639866ca1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
            "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
            "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
            "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
            "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan daftar karyawan yang bekerja di departemen `Finance`, dan tampilkan gaji tertinggi (`max salary`) dari karyawan yang bekerja di departemen `Finance` menggunakan `pyspark` dataframe."
      ],
      "metadata": {
        "id": "GKw81nu2xS37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cara 1: Menggunakan SQL Query"
      ],
      "metadata": {
        "id": "nolH9UDpHPk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joined_df.createOrReplaceTempView(\"join_table\") # Buat view baru\n",
        "\n",
        "result1 = spark.sql(\"SELECT name FROM join_table WHERE dept_name='Finance'\")\n",
        "print(\"== Daftar karyawan yang bekerja di departemen Finance ==\")\n",
        "result1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiU4-6kXHSIU",
        "outputId": "9588ac6c-812e-4eff-ab36-989677d05abe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Daftar karyawan yang bekerja di departemen Finance ==\n",
            "+--------+\n",
            "|    name|\n",
            "+--------+\n",
            "|   Smith|\n",
            "|Williams|\n",
            "|   Jones|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result2 = spark.sql(\"SELECT name, salary FROM join_table WHERE dept_name='Finance' AND salary = (SELECT max(salary) FROM join_table WHERE dept_name='Finance')\")\n",
        "print(\"== Daftar karyawan yang bekerja di departemen Finance yang memiliki gaji tertinggi ==\")\n",
        "result2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh1pukyDIdXE",
        "outputId": "2cb9f662-d745-491f-c8f2-983bc0bd3dc7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Daftar karyawan yang bekerja di departemen Finance yang memiliki gaji tertinggi ==\n",
            "+-----+------+\n",
            "| name|salary|\n",
            "+-----+------+\n",
            "|Smith|  3000|\n",
            "+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cara 2: Menggunakan query dari Spark"
      ],
      "metadata": {
        "id": "QfRXbr73LKe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import fungsi max\n",
        "from pyspark.sql.functions import max"
      ],
      "metadata": {
        "id": "Z8jQ0ObxGn9T"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result3 = joined_df.filter(joined_df.dept_name == 'Finance').select(\"name\")\n",
        "result3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWGj4T3qz_u1",
        "outputId": "3c5500b6-86d1-47f3-f1d7-36c6d54d88c2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|    name|\n",
            "+--------+\n",
            "|   Smith|\n",
            "|Williams|\n",
            "|   Jones|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dapatkan salary tertinggi di departemen Finance\n",
        "max_salary_in_finance = joined_df.filter(\"dept_name == 'Finance'\").select(max(\"salary\")).collect()[0]['max(salary)']\n",
        "# Print bersama dengan nama\n",
        "result4 = joined_df.filter((joined_df.dept_name == \"Finance\") & (joined_df.salary == max_salary_in_finance)).select(\"name\", \"salary\")\n",
        "result4.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-nmDkOZY9OB",
        "outputId": "5bb1c10e-a3d4-4def-9dce-086b25a5eeae"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+\n",
            "| name|salary|\n",
            "+-----+------+\n",
            "|Smith|  3000|\n",
            "+-----+------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}